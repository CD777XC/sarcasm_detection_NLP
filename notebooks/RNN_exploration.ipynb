{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db53a70-ffda-4705-a7be-fc76b2f4e9dc",
   "metadata": {
    "id": "8db53a70-ffda-4705-a7be-fc76b2f4e9dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 07:13:13.263048: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 07:13:13.265426: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 07:13:13.272578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-27 07:13:13.285249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-27 07:13:13.288849: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-27 07:13:13.298314: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 07:13:14.166749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bb8032-c01f-4749-bb02-1f1dbfab10ed",
   "metadata": {
    "id": "98bb8032-c01f-4749-bb02-1f1dbfab10ed"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4qnpxv1eUO9m",
   "metadata": {
    "id": "4qnpxv1eUO9m"
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv('../clean_data/sarcasm_headlines_v2_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nBnMf1KaUXU9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nBnMf1KaUXU9",
    "outputId": "06a02c30-773f-4d3a-c1d6-613c2333aff1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientist unveil doomsday cloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep totally nail why congress be fall shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggie deliciously different recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevent liar from get to work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother come pretty close to use word stream co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                   cleaned_headline\n",
       "0             1  thirtysomething scientist unveil doomsday cloc...\n",
       "1             0  dem rep totally nail why congress be fall shor...\n",
       "2             0       eat your veggie deliciously different recipe\n",
       "3             1    inclement weather prevent liar from get to work\n",
       "4             1  mother come pretty close to use word stream co..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if dataset is correctly loaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grFQFYUsUYUK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grFQFYUsUYUK",
    "outputId": "f2cf80a6-ca3e-4b49-d10b-d3f00b153b32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edCZjOVyWSBJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edCZjOVyWSBJ",
    "outputId": "e3b842cf-6fd2-462b-8f79-3d9443bc98dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking max length\n",
    "len(df['cleaned_headline'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "E90ZJ889Uk-H",
   "metadata": {
    "id": "E90ZJ889Uk-H"
   },
   "outputs": [],
   "source": [
    "# Model parms\n",
    "max_len = 100\n",
    "embedding_dim = 300\n",
    "max_features = 5000\n",
    "num_filters = 32\n",
    "\n",
    "# Model fit params\n",
    "batch_size = 128\n",
    "num_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ByCrrp-XPyQ",
   "metadata": {
    "id": "6ByCrrp-XPyQ"
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df['cleaned_headline']\n",
    "y = df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be24a19-d2b9-4633-bff1-7d2b4b53400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenizing\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Converting words to integers\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding the sequences\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3Aa6Xt-vV59b",
   "metadata": {
    "id": "3Aa6Xt-vV59b"
   },
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, y, test_size=.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa34219-8f12-4dc2-90c1-0be9ff004901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20033, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcca955e-70bc-4fd4-9060-9c609d9ccce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in df['cleaned_headline'].values:\n",
    "    words.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92fca8b4-4714-4b6f-83fd-e7f088eac96c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'Word2Vec' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, i \u001b[38;5;129;01min\u001b[39;00m word_index\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m max_features:\n\u001b[0;32m---> 13\u001b[0m         embedding_vector \u001b[38;5;241m=\u001b[39m word2vec\u001b[38;5;241m.\u001b[39mget_vector(word) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw2v_model\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m embedding_vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m             embedding_matrix[i] \u001b[38;5;241m=\u001b[39m embedding_vector\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'Word2Vec' is not iterable"
     ]
    }
   ],
   "source": [
    "# Importing word2vec model\n",
    "import gensim\n",
    "\n",
    "# Load pre-trained Word2Vec model.\n",
    "w2v_model = gensim.models.Word2Vec(sentences=words, window = 5, min_count = 1)\n",
    "\n",
    "# Create an embedding matrix\n",
    "embedding_dim = 300  # Word2Vec Google News vectors have 300 dimensions\n",
    "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < max_features:\n",
    "        embedding_vector = word2vec.get_vector(word) if word in w2v_model else None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61b95c-fe03-4619-838f-fce275ca4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_features, embedding_dim, weights=[embedding_matrix], input_length=max_len),  # Embedding layer\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),  # Bidirectional LSTM\n",
    "    Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    LSTM(32),  # Another LSTM layer\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),  # Fully connected layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e1846-e924-427c-a2ae-3a74c2b60551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Defining early stopping params\n",
    "es = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 5,\n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66d17f-0b39-40eb-a04d-9fe87d09b726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model2.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[es])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb49e82-cf6d-4b34-979f-52c16a307e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[es])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be649c9b-9cf5-4aa9-b56f-2901b51d6c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
