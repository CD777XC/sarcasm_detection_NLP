{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db53a70-ffda-4705-a7be-fc76b2f4e9dc",
   "metadata": {
    "id": "8db53a70-ffda-4705-a7be-fc76b2f4e9dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 21:13:42.261837: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-11 21:13:42.374979: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-11 21:13:42.488869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-11 21:13:42.578638: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-11 21:13:42.604061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-11 21:13:42.780078: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 21:13:44.320500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98bb8032-c01f-4749-bb02-1f1dbfab10ed",
   "metadata": {
    "id": "98bb8032-c01f-4749-bb02-1f1dbfab10ed"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4qnpxv1eUO9m",
   "metadata": {
    "id": "4qnpxv1eUO9m"
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv('../clean_data/sarcasm_headlines_v2_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nBnMf1KaUXU9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nBnMf1KaUXU9",
    "outputId": "06a02c30-773f-4d3a-c1d6-613c2333aff1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientist unveil doomsday cloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep totally nail why congress be fall shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggie deliciously different recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevent liar from get to work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother come pretty close to use word stream co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                   cleaned_headline\n",
       "0             1  thirtysomething scientist unveil doomsday cloc...\n",
       "1             0  dem rep totally nail why congress be fall shor...\n",
       "2             0       eat your veggie deliciously different recipe\n",
       "3             1    inclement weather prevent liar from get to work\n",
       "4             1  mother come pretty close to use word stream co..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if dataset is correctly loaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grFQFYUsUYUK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grFQFYUsUYUK",
    "outputId": "f2cf80a6-ca3e-4b49-d10b-d3f00b153b32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edCZjOVyWSBJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edCZjOVyWSBJ",
    "outputId": "e3b842cf-6fd2-462b-8f79-3d9443bc98dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking max length\n",
    "len(df['cleaned_headline'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "E90ZJ889Uk-H",
   "metadata": {
    "id": "E90ZJ889Uk-H"
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "max_len = 100\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ByCrrp-XPyQ",
   "metadata": {
    "id": "6ByCrrp-XPyQ"
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df['cleaned_headline']\n",
    "y = df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bNio6DOaazyV",
   "metadata": {
    "id": "bNio6DOaazyV"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tokenizing\n",
    "tfid_vectorizer = TfidfVectorizer(max_df = 0.75, max_features = 7000, ngram_range=(1,2))\n",
    "X_processed = pd.DataFrame(tfid_vectorizer.fit_transform(df['cleaned_headline']).toarray(),\n",
    "                              columns=tfid_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cad32714-5d19-4449-8b88-9ae73435dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# # Tokenization and padding\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(X)\n",
    "# word_index = tokenizer.word_index\n",
    "\n",
    "# X_tokenized = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# X_padded = pad_sequences(X_tokenized, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7691847e-dec2-4612-94fa-cdc47459ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure VOCAB_SIZE is correct\n",
    "# vocab_size = len(word_index) + 1  # Adding 1 to include the padding index\n",
    "\n",
    "# # Check and adjust indices\n",
    "# X_processed = np.clip(X_padded, 0, VOCAB_SIZE - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3Aa6Xt-vV59b",
   "metadata": {
    "id": "3Aa6Xt-vV59b"
   },
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfa34219-8f12-4dc2-90c1-0be9ff004901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20033, 7000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ddb2554-367b-4b90-8cf2-033f21e1d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciating model\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c3e1846-e924-427c-a2ae-3a74c2b60551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66d17f-0b39-40eb-a04d-9fe87d09b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m 17/157\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:35\u001b[0m 6s/step - accuracy: 0.5229 - loss: 0.6922"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=3, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb832fc-106f-4a4a-8b9e-5e2e927ad3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
